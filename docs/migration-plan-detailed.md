# Детальный план миграции на новый API avito-library

> Документ создан на основе глубокого анализа текущей реализации и актуальной документации библиотеки.

---

## Оглавление

1. [Общая информация](#1-общая-информация)
2. [Что изменилось в библиотеке](#2-что-изменилось-в-библиотеке)
3. [Текущая архитектура системы](#3-текущая-архитектура-системы)
4. [Детальный план изменений по файлам](#4-детальный-план-изменений-по-файлам)
5. [Вопросы, требующие решения](#5-вопросы-требующие-решения)
6. [Порядок выполнения миграции](#6-порядок-выполнения-миграции)
7. [Риски и как их избежать](#7-риски-и-как-их-избежать)

---

## 1. Общая информация

### Цель миграции

Перевести систему парсинга с устаревшего API библиотеки avito-library на актуальный. Старый API использовал механизм "запрос-ответ" через `wait_for_page_request` и `supply_page`, новый API использует более простой подход с методом `continue_from()` для продолжения после ошибок.

### Затрагиваемые компоненты

| Компонент | Степень изменений | Описание |
|-----------|-------------------|----------|
| `browser_worker.py` | Значительные | Основная логика парсинга каталогов и карточек |
| `catalog_parser.py` | Средние | Обёртка над функцией парсинга каталога |
| `object_parser.py` | Небольшие | Маппинг данных карточки в БД |
| `config.py` | Минимальные | Исправление имени поля |
| `detectors.py` | Минимальные | Удаление несуществующей функции из экспорта |
| `detector_handler.py` | Удаление/упрощение | Логика перенесена в библиотеку |
| `server_error_detector.py` | Удаление | Библиотека делает это сама |

---

## 2. Что изменилось в библиотеке

### 2.1. Парсинг каталога

**Было (старый API):**
- Функция `parse_catalog_until_complete()` из внутреннего модуля
- Механизм обратного вызова через `wait_for_page_request()` и `supply_page()`
- При блокировке прокси библиотека "просила" новую страницу через этот механизм
- Воркер должен был запускать фоновую задачу `page_provider_loop` для обработки запросов

**Стало (новый API):**
- Функция `parse_catalog()` из корневого модуля
- Возвращает объект `CatalogParseResult` со статусом и данными
- При блокировке прокси — просто возвращает статус `PROXY_BLOCKED`
- Для продолжения — вызвать `result.continue_from(new_page)` с новой страницей
- Никаких фоновых задач, всё синхронно и предсказуемо

**Изменения в параметрах:**
- `sort_by_date=True` заменён на `sort="date"`
- Добавлен параметр `condition` для фильтрации по состоянию товара ("Новый" / "С пробегом")

### 2.2. Парсинг карточки объявления

**Было (старый API):**
- Синхронная функция `parse_card(html, fields=..., ensure_card=True)`
- Принимала HTML-строку
- Выбрасывала исключение `CardParsingError` при проблемах
- Воркер сам делал детекцию состояния страницы и решение капчи

**Стало (новый API):**
- Асинхронная функция `await parse_card(page, response, fields=...)`
- Принимает Playwright Page и Response
- Возвращает `CardParseResult` со статусом (никаких исключений)
- Библиотека сама делает детекцию, retry и решение капчи
- Воркеру нужно только обработать финальный статус

### 2.3. Новые статусы

**Для каталога (CatalogParseStatus):**

| Статус | Описание | Действие воркера |
|--------|----------|------------------|
| `SUCCESS` | Успешно спарсено | Сохранить данные, завершить задачу |
| `EMPTY` | Каталог пуст (0 объявлений) | Завершить задачу без сохранения |
| `PROXY_BLOCKED` | Прокси заблокирован (HTTP 403) | Заблокировать прокси, продолжить с новым |
| `PROXY_AUTH_REQUIRED` | Ошибка авторизации прокси (HTTP 407) | Заблокировать прокси, продолжить с новым |
| `CAPTCHA_FAILED` | Капча не решена | Вернуть задачу и прокси в пулы |
| `PAGE_NOT_DETECTED` | Неизвестное состояние страницы | Пометить задачу как failed |
| `WRONG_PAGE` | Открыта не та страница | Пометить задачу как failed |
| `LOAD_TIMEOUT` | Таймаут загрузки | Вернуть задачу, увеличить счётчик ошибок прокси |
| `SERVER_UNAVAILABLE` | Сервер Avito недоступен (502/503/504) | Вернуть задачу (не блокировать прокси!) |

**Для карточки (CardParseStatus):**

| Статус | Описание | Действие воркера |
|--------|----------|------------------|
| `SUCCESS` | Успешно спарсено | Сохранить данные, завершить задачу |
| `PROXY_BLOCKED` | Прокси заблокирован | Заблокировать прокси, вернуть задачу |
| `NOT_FOUND` | Объявление удалено (404/410) | Пометить задачу как invalid |
| `CAPTCHA_FAILED` | Капча не решена | Вернуть задачу и прокси в пулы |
| `PAGE_NOT_DETECTED` | Неизвестное состояние | Пометить задачу как failed |
| `WRONG_PAGE` | Не та страница | Пометить задачу как failed |
| `SERVER_UNAVAILABLE` | Сервер недоступен | Вернуть задачу (не блокировать прокси!) |

### 2.4. Переименованные статусы

При миграции нужно заменить старые названия на новые:

| Старое название | Новое название |
|-----------------|----------------|
| `CAPTCHA_UNSOLVED` | `CAPTCHA_FAILED` |
| `NOT_DETECTED` | `PAGE_NOT_DETECTED` |

### 2.5. Детектор серверных ошибок

**Было:**
- Библиотека не обрабатывала 502/503/504
- В проекте был кастомный `server_error_detector.py`
- Воркер сам делал retry при серверных ошибках

**Стало:**
- Библиотека имеет встроенный `SERVER_ERROR_5XX_DETECTOR_ID`
- Библиотека автоматически делает retry
- Если retry исчерпаны — возвращает статус `SERVER_UNAVAILABLE`
- Кастомный детектор больше не нужен

### 2.6. Изменения в структуре данных карточки

**Структура `seller`:**

| Было | Стало |
|------|-------|
| `name` | `name` (без изменений) |
| `id` | Удалено |
| `rating` | Удалено |
| — | `profile_url` (новое) |

**Структура `location`:**

| Было | Стало |
|------|-------|
| `name` | Удалено |
| `coords` | Удалено |
| — | `address` (новое) |
| — | `metro` (новое) |
| — | `region` (новое) |

Поскольку эти данные не являются критичными для проекта, новые колонки в БД создавать не требуется. Просто адаптируем маппинг, чтобы код не падал.

---

## 3. Текущая архитектура системы

### 3.1. Общая схема

```
MainProcess
    │
    ├── Создаёт catalog_tasks для NEW артикулов
    ├── Создаёт object_tasks для VALIDATED артикулов
    ├── Запускает BrowserWorker'ы (парсинг)
    ├── Запускает ValidationWorker'ы (валидация)
    └── Мониторит heartbeat зависших задач

BrowserWorker (несколько экземпляров)
    │
    ├── Берёт catalog_task → парсит каталог → сохраняет catalog_listings
    └── Берёт object_task → парсит карточку → сохраняет object_data

ValidationWorker (несколько экземпляров)
    │
    └── Берёт артикул в CATALOG_PARSED → валидирует → создаёт object_tasks
```

### 3.2. State Machine артикулов

```
NEW
 │
 ▼ (BrowserWorker берёт catalog_task)
CATALOG_PARSING
 │
 ▼ (каталог успешно спарсен)
CATALOG_PARSED
 │
 ▼ (ValidationWorker берёт на валидацию)
VALIDATING
 │
 ├──▶ VALIDATED (достаточно валидных объявлений)
 │       │
 │       ▼ (BrowserWorker берёт object_task)
 │    OBJECT_PARSING (финальное состояние)
 │
 └──▶ REJECTED_BY_MIN_COUNT (недостаточно объявлений, финальное)
```

### 3.3. Жизненный цикл catalog_task (текущий)

1. MainProcess создаёт задачу для артикула в состоянии NEW
2. BrowserWorker берёт задачу через `acquire_catalog_task()`
3. Артикул переходит в CATALOG_PARSING
4. Запускается фоновая задача `page_provider_loop`
5. Вызывается `parse_catalog_until_complete()`
6. При блокировке прокси — `page_provider_loop` меняет прокси и отдаёт новую страницу
7. По завершении — сохраняются listings, артикул переходит в CATALOG_PARSED

### 3.4. Жизненный цикл catalog_task (новый)

1. MainProcess создаёт задачу для артикула в состоянии NEW
2. BrowserWorker берёт задачу через `acquire_catalog_task()`
3. Артикул переходит в CATALOG_PARSING
4. Вызывается `parse_catalog()` — возвращает результат
5. Если `PROXY_BLOCKED` — блокируем прокси, создаём новую страницу, вызываем `continue_from()`
6. Повторяем пункт 5 пока не получим финальный статус
7. По завершении — обрабатываем результат в зависимости от статуса

**Ключевое отличие:** Никаких фоновых задач, вся логика линейная и простая.

---

## 4. Детальный план изменений по файлам

### 4.1. Файлы для удаления

#### `container/server_error_detector.py`

**Причина удаления:** Библиотека теперь сама обрабатывает серверные ошибки (502/503/504) и возвращает статус `SERVER_UNAVAILABLE` если retry исчерпаны.

**Что было в файле:**
- Константы `SERVER_ERROR_502_DETECTOR_ID`, `SERVER_ERROR_503_DETECTOR_ID`, `SERVER_ERROR_504_DETECTOR_ID`
- Функция `detect_server_error()` — проверка HTTP статуса и текста страницы
- Функция `is_server_error()` — проверка является ли детектор серверной ошибкой
- Функция `get_server_error_description()` — описание ошибки

**После удаления:** Все ссылки на этот модуль нужно убрать из других файлов.

---

### 4.2. Файлы для значительной переработки

#### `container/browser_worker.py`

Это основной файл, который требует наибольших изменений.

**Изменения в импортах:**

Убрать:
- `wait_for_page_request` — больше не используется
- `supply_page` — больше не используется
- `CardParsingError` — новый API не выбрасывает исключения

Добавить:
- `parse_catalog` из корневого модуля `avito_library`
- `CatalogParseResult` — тип результата парсинга каталога
- `CardParseResult` — тип результата парсинга карточки
- `CardParseStatus` — статусы парсинга карточки

Убрать импорты из `server_error_detector`:
- `detect_server_error`
- `is_server_error`
- `get_server_error_description`
- Все константы `SERVER_ERROR_*`

Убрать импорты из `detector_handler`:
- `handle_detector_state`
- `DetectorContext`
- `enhanced_detect_page_state`

**Удалить метод `page_provider_loop`:**

Этот метод (строки 240-276) больше не нужен. Он обрабатывал запросы от старой функции `parse_catalog_until_complete`. Новый API не использует этот механизм.

**Переписать метод `process_catalog_task`:**

Текущая логика:
1. Запуск фоновых задач heartbeat и page_provider
2. Вызов `parse_catalog_for_articulum()`
3. Обработка результата
4. Остановка фоновых задач

Новая логика:
1. Запуск только heartbeat (page_provider не нужен)
2. Вызов `parse_catalog()` напрямую
3. Цикл обработки: если `PROXY_BLOCKED` — сменить прокси и вызвать `continue_from()`
4. Обработка финального результата
5. Остановка heartbeat

Ключевые моменты новой реализации:
- Проверять `result.status in {SUCCESS, EMPTY}` для успешного завершения
- При `PROXY_BLOCKED` или `PROXY_AUTH_REQUIRED` — цикл со сменой прокси
- При `SERVER_UNAVAILABLE` — вернуть задачу, НЕ блокировать прокси
- Сохранять checkpoint через `result.resume_page_number` после каждого `continue_from`

**Переписать метод `process_object_task`:**

Текущая логика:
1. Переход на страницу карточки
2. Вызов `enhanced_detect_page_state()` — ручная детекция
3. Retry при server errors (кастомный код)
4. Вызов `handle_detector_state()` — обработка состояния
5. Получение HTML и вызов синхронного `parse_card(html, ...)`
6. Обработка `CardParsingError`

Новая логика:
1. Переход на страницу карточки (`page.goto()`)
2. Вызов `await parse_card(page, response, fields=...)` — асинхронный
3. Обработка `result.status` напрямую (без промежуточных обработчиков)

Библиотека сама делает:
- Детекцию состояния страницы
- Решение капчи
- Retry при серверных ошибках

Воркеру остаётся только обработать финальный статус.

**Удалить retry логику для server errors:**

Строки 477-510 содержат ручной retry при обнаружении 502/503/504. Эта логика больше не нужна — библиотека делает retry автоматически.

**Обновить метод `handle_parse_result`:**

Изменения:
- Добавить обработку `EMPTY` — аналогично `SUCCESS`, но без сохранения данных
- Переименовать `CAPTCHA_UNSOLVED` → `CAPTCHA_FAILED`
- Переименовать `NOT_DETECTED` → `PAGE_NOT_DETECTED`
- Добавить обработку `SERVER_UNAVAILABLE` — вернуть задачу без блокировки прокси

---

#### `container/detector_handler.py`

**Варианты действий:**

1. **Удалить полностью** — вся логика теперь в библиотеке
2. **Оставить как хелпер** — если нужны функции типа `get_detector_description()`

**Рекомендация:** Удалить полностью. Функции описания детекторов можно перенести в `detectors.py` если они где-то используются.

**Что удаляем:**
- Класс `DetectorContext` — больше не нужен
- Функция `enhanced_detect_page_state()` — библиотека делает это сама
- Функция `handle_detector_state()` — логика перенесена в воркер
- Функция `_handle_captcha()` — библиотека решает капчу сама

---

### 4.3. Файлы для средних изменений

#### `container/catalog_parser.py`

**Изменения в импортах:**

Убрать:
- `parse_catalog_until_complete` из внутреннего модуля

Добавить:
- `parse_catalog` из корневого `avito_library`
- `CatalogParseResult`

**Изменить функцию `parse_catalog_for_articulum`:**

Текущая сигнатура:
```python
async def parse_catalog_for_articulum(page, articulum, start_page=1) -> Tuple[List[CatalogListing], CatalogParseMeta]
```

Новая сигнатура:
```python
async def parse_catalog_for_articulum(page, articulum, start_page=1) -> CatalogParseResult
```

Изменения внутри:
- `parse_catalog_until_complete()` → `parse_catalog()`
- `sort_by_date=True` → `sort="date"`
- Возвращать `CatalogParseResult` целиком вместо распаковки в tuple

**Альтернатива:** Можно вообще удалить эту функцию-обёртку и вызывать `parse_catalog()` напрямую из воркера. Обёртка делает только построение URL и передачу параметров из конфига.

---

#### `container/object_parser.py`

**Изменения в маппинге данных:**

Структура `seller` изменилась:
- `card_data.seller.get('id')` → `None` (поля больше нет)
- `card_data.seller.get('rating')` → `None` (поля больше нет)
- `card_data.seller.get('name')` — без изменений

Структура `location` изменилась:
- `card_data.location.get('name')` → `card_data.location.get('address')`
- `card_data.location.get('coords')` → `None` (поля больше нет)

Код не упадёт, потому что используется `.get()` с возвратом `None` по умолчанию. Но лучше явно обновить маппинг для ясности.

---

### 4.4. Файлы для минимальных изменений

#### `container/config.py`

**Единственное изменение:**

Строка 60:
```python
# Было:
'snippet',  # не snippet_text!

# Станет:
'snippet_text',
```

Комментарий в текущем коде ошибочен. Документация библиотеки чётко указывает, что поле называется `snippet_text`. В БД колонка тоже называется `snippet_text`. Нужно исправить.

---

#### `container/detectors.py`

**Изменения:**

1. Удалить `press_continue_and_detect` из списка `__all__` — этой функции нет в модуле

2. Опционально добавить новую константу `SERVER_ERROR_5XX_DETECTOR_ID` в импорты (если будет использоваться где-то)

3. Опционально обновить функцию `get_detector_description()` — добавить описание для нового детектора

---

## 5. Вопросы, требующие решения

### Вопрос A: Обработка SERVER_UNAVAILABLE

**Контекст:** Когда сервер Avito возвращает 502/503/504, библиотека делает несколько попыток retry. Если все попытки исчерпаны, возвращается статус `SERVER_UNAVAILABLE`.

**Варианты действий:**

| Вариант | Описание | Плюсы | Минусы |
|---------|----------|-------|--------|
| 1 | Вернуть задачу, оставить прокси | Простота | Тот же прокси может снова получить ошибку |
| 2 | Вернуть задачу, освободить прокси | Другой воркер попробует с другим прокси | Текущий воркер потеряет прокси |
| 3 | Вернуть задачу, сменить прокси | Текущий воркер попробует с другим IP | Сложнее в реализации |

**Рекомендация:** Вариант 2 — вернуть задачу и освободить прокси (но НЕ блокировать). Это проблема сервера Avito, а не прокси.

---

### Вопрос B: Сохранение checkpoint при continue_from

**Контекст:** В старом API `page_provider_loop` сохранял checkpoint после каждой страницы. Если воркер падал, задача возобновлялась с последней сохранённой страницы.

**Вопрос:** Нужно ли сохранять `result.resume_page_number` в БД после каждого `continue_from`?

**Рекомендация:** Да, это полезно для recovery. После каждого успешного `continue_from` сохранять checkpoint в `catalog_tasks.checkpoint_page`.

---

### Вопрос C: Использование параметра condition

**Контекст:** Новый API поддерживает параметр `condition` для фильтрации по состоянию товара:
- `condition="Новый"` — только новые товары
- `condition="С пробегом"` — только б/у

**Вопрос:** Нужно ли добавить этот параметр в конфигурацию и использовать при парсинге каталога?

**Рекомендация:** Пока не добавлять. Текущая логика валидации уже отфильтровывает б/у товары через стоп-слова и проверку характеристик.

---

### Вопрос D: Проверка "б/у" в характеристиках карточки

**Контекст:** В `browser_worker.py` есть метод `_is_used_condition()`, который проверяет характеристики карточки на наличие состояния "б/у".

**Вопрос:** Оставить эту проверку или она избыточна?

**Рекомендация:** Оставить как дополнительную защиту. Даже если в будущем добавим фильтр `condition="Новый"`, эта проверка подстрахует на случай если фильтр каталога не сработает.

---

## 6. Порядок выполнения миграции

### Этап 1: Подготовка

1. Создать резервную копию всех изменяемых файлов
2. Убедиться, что библиотека avito-library обновлена до актуальной версии
3. Проверить, что тесты проходят на текущей версии

### Этап 2: Изменения без риска (не влияют на работу)

1. Исправить `config.py` — `snippet` → `snippet_text`
2. Исправить `detectors.py` — удалить `press_continue_and_detect` из `__all__`
3. Удалить `server_error_detector.py`

### Этап 3: Изменения catalog_parser.py

1. Обновить импорты
2. Изменить функцию `parse_catalog_for_articulum`
3. Протестировать сборку (без запуска воркеров)

### Этап 4: Изменения object_parser.py

1. Обновить маппинг seller и location
2. Протестировать сборку

### Этап 5: Изменения browser_worker.py (основная часть)

1. Обновить импорты
2. Удалить `page_provider_loop`
3. Переписать `process_catalog_task`
4. Переписать `handle_parse_result`
5. Переписать `process_object_task`
6. Удалить retry логику для server errors

### Этап 6: Удаление detector_handler.py

1. Убедиться, что все ссылки на модуль удалены
2. Удалить файл

### Этап 7: Тестирование

1. Запустить один BrowserWorker в изолированном режиме
2. Проверить парсинг каталога (успех, пустой каталог, блокировка прокси)
3. Проверить парсинг карточки (успех, удалённое объявление, блокировка)
4. Проверить обработку SERVER_UNAVAILABLE (если получится воспроизвести)
5. Запустить полную систему и мониторить логи

---

## 7. Риски и как их избежать

### Риск 1: Потеря checkpoint при смене прокси

**Описание:** Если воркер упадёт во время цикла `continue_from`, задача может начаться с первой страницы вместо последней обработанной.

**Решение:** Сохранять `result.resume_page_number` в БД после каждого успешного `continue_from`.

---

### Риск 2: Несовместимость структуры данных

**Описание:** Если библиотека изменила структуру `CatalogListing` или `CardData`, код может упасть при обращении к несуществующим полям.

**Решение:**
- Использовать `.get()` вместо прямого доступа к полям
- Перед миграцией залогировать реальную структуру объектов на тестовых данных

---

### Риск 3: Бесконечный цикл при смене прокси

**Описание:** Если все прокси заблокированы, цикл `continue_from` может работать бесконечно.

**Решение:** Добавить счётчик попыток смены прокси (например, максимум 10). После исчерпания — вернуть задачу в очередь.

---

### Риск 4: Race condition при обновлении checkpoint

**Описание:** Если heartbeat и сохранение checkpoint происходят одновременно, могут быть конфликты.

**Решение:** Использовать одно соединение к БД для обеих операций или добавить блокировку.

---

### Риск 5: Утечка ресурсов при смене прокси

**Описание:** При создании нового браузера старый может не закрыться корректно.

**Решение:** Использовать try/finally для гарантированного закрытия. Текущий код уже делает это в `recreate_page_with_new_proxy`.

---

## Приложение: Сводная таблица изменений

| Файл | Действие | Сложность | Приоритет |
|------|----------|-----------|-----------|
| `config.py` | Исправить поле | Низкая | 1 |
| `detectors.py` | Удалить из __all__ | Низкая | 1 |
| `server_error_detector.py` | Удалить файл | Низкая | 2 |
| `catalog_parser.py` | Переписать функцию | Средняя | 3 |
| `object_parser.py` | Обновить маппинг | Низкая | 4 |
| `detector_handler.py` | Удалить файл | Низкая | 5 |
| `browser_worker.py` | Значительные изменения | Высокая | 6 |

---

*Документ будет обновляться по мере уточнения деталей и принятия решений по открытым вопросам.*
