# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

**ОБЯЗАТЕЛЬНО НАДО ПЕРИОДИЧЕСКИ ОБНОВЛЯТЬ И ДОБАВЛЯТЬ ИНФОРМАЦИЮ В ЭТОТ ФАЙЛ И СЛЕДИТЬ ЗА ТЕМ, ЧТОБЫ ИНФОРМАЦИЯ НЕ ПРОТИВОРЕЧИЛА РЕАЛЬНОСТИ И ПРОЧИМ ДОКУМЕНТАЦИЯМ**

ОБЯЗАТЕЛЬНО ВСЕ РЕАЛИЗУЕМ ПО ПРИНЦИПАМ KISS и DRY
КОД И ЛОГИКА НЕ ДОЛЖНЫ ДУБЛИРОВАТЬСЯ, ВСЕ ДОЛЖНО БЫТЬ МАКСИМЛЬНО ПРОСТЫМ

---

## КОМАНДЫ ДЛЯ РАЗРАБОТКИ

### Настройка базы данных (из корня проекта)
```bash
# Создать схему БД (таблицы создаются автоматически при первом запуске)
python scripts/create_db.py

# Загрузить артикулы из файла
python scripts/load_articulums.py scripts/data/articulums.txt --mode add
# Режимы: add (добавить), replace (заменить все)

# Загрузить прокси из файла (формат: host:port:username:password)
python scripts/load_proxies.py scripts/data/proxies.txt --mode add
# Режимы: add (добавить), replace (заменить все)

# Загрузить фильтр объявлений для повторного парсинга (по одному avito_item_id на строку)
python scripts/load_filter_items.py scripts/data/filter_items.txt --mode add
# Режимы: add (добавить), replace (заменить все)

# Загрузить фильтр артикулов для повторного парсинга (по одному артикулу на строку)
python scripts/load_filter_articulums.py scripts/data/filter_articulums.txt --mode add
# Режимы: add (добавить), replace (заменить все)

# Очистить таблицы
python scripts/clear_tables.py --mode select  # Интерактивный выбор
python scripts/clear_tables.py --mode all     # Очистить все (с подтверждением)

# Посмотреть статус системы
python scripts/dashboard.py

# Сгенерировать аналитический отчет по артикулам
python scripts/articulum_report.py
# Создает таблицу analytics_articulum_report с детальной информацией по каждому объявлению:
# - результаты валидации на каждом этапе (price_filter, mechanical, ai)
# - причины отклонения
# - итоговый статус (прошло/отклонено)
# Фильтр артикулов: scripts/data/report_articulums.txt (один артикул на строку)
# Если файл пустой - отчет генерируется по ВСЕМ артикулам из БД

# Миграция для поддержки multi-server развертывания
python scripts/migrate_worker_id.py
# ВАЖНО: Запускать ТОЛЬКО при обновлении существующей БД
# Останавливает все контейнеры перед миграцией

# Миграция для добавления счетчика ошибок прокси
python scripts/migrate_proxy_errors.py
# ВАЖНО: Запускать ТОЛЬКО при обновлении существующей БД
# Добавляет поля consecutive_errors и last_error_at в таблицу proxies
# Останавливает все контейнеры перед миграцией
```

### Запуск системы (ИЗ КАТАЛОГА container/)
```bash
# ВАЖНО: Все docker compose команды только из container/
cd container/

# Запустить систему
docker compose up -d

# Посмотреть логи
docker compose logs -f parser

# Остановить систему
docker compose down

# Перезапустить
docker compose restart parser

# Пересобрать образ (после изменений в коде)
docker compose up -d --build
```

### Конфигурация через docker-compose.yml

Все параметры системы задаются через переменные окружения в [docker-compose.yml](container/docker-compose.yml):

**Воркеры:**
- `TOTAL_BROWSER_WORKERS` - Общее количество Browser Workers (default: 3)
- `TOTAL_VALIDATION_WORKERS` - Количество Validation Workers (default: 5)
- `CATALOG_BUFFER_SIZE` - Размер буфера каталогов (default: 5)
  - Минимум артикулов со спарсенными каталогами, готовых к парсингу объявлений
  - Если buffer < CATALOG_BUFFER_SIZE → воркеры приоритезируют catalog задачи
  - Если buffer >= CATALOG_BUFFER_SIZE → воркеры приоритезируют object задачи
  - Обеспечивает баланс между парсингом каталогов и объявлений

**Валидация:**
- `MIN_PRICE` - Минимальная цена объявления (default: 1000.0)
- `MIN_VALIDATED_ITEMS` - Мин. количество после каждого этапа валидации (default: 3)
- `MIN_SELLER_REVIEWS` - Мин. количество отзывов продавца (default: 0, отключено)
- `ENABLE_PRICE_VALIDATION` - Включить валидацию по цене (default: true)
  - IQR метод для автоматического определения аномально дорогих выбросов
  - Проверка подозрительно дешевых (< 50% медианы топ-40% чистых цен)
- `REQUIRE_ARTICULUM_IN_TEXT` - Требовать наличие артикула в названии или описании для механической валидации (default: true)
  - Нормализация текста: lowercase + замена русских букв на английские + удаление спецсимволов
  - Поиск в title и snippet_text
  - ИИ валидация ВСЕГДА проверяет соответствие артикулу независимо от этого флага
  - Объявления без артикула отклоняются на этапе механической валидации
- `GEMINI_API_KEY` - API ключ Gemini для ИИ-валидации (обязателен)

**Парсинг каталогов:**
- `CATALOG_MAX_PAGES` - Макс. страниц каталога (default: 10)
- `CATALOG_INCLUDE_HTML` - Сохранять raw HTML (default: false)

**Парсинг объявлений:**
- `OBJECT_INCLUDE_HTML` - Сохранять raw HTML карточек (default: false)
- Автоматическая фильтрация объявлений с состоянием "б/у" в характеристиках
  - Проверяется поле "Состояние" (или "Condition") в characteristics
  - Поддерживаются все варианты написания: б/у, бу, б.у., БУ и т.д.
  - Отклоненные объявления помечаются как invalid с причиной

**Режим повторного парсинга:**
- `REPARSE_MODE` - Режим повторного парсинга (только ранее спарсенные объявления) (default: false)
- `MIN_REPARSE_INTERVAL_HOURS` - Минимальный интервал между парсингами одного объявления в часах (default: 24)

**Heartbeat:**
- `HEARTBEAT_TIMEOUT_SECONDS` - Таймаут задачи (default: 1800)
- `HEARTBEAT_UPDATE_INTERVAL` - Интервал обновления воркером (default: 60)
- `HEARTBEAT_CHECK_INTERVAL` - Интервал проверки фоновой задачей (default: 120)

### Структура проекта
```
z/
├── container/                  # Основная логика (ЗДЕСЬ docker-compose.yml)
│   ├── main.py                # Главный процесс-оркестратор
│   ├── browser_worker.py      # Browser Worker (парсинг каталогов/объявлений)
│   ├── catalog_parser.py      # Парсинг каталогов через avito-library
│   ├── catalog_task_manager.py # Управление очередью catalog_tasks
│   ├── object_parser.py       # Парсинг карточек объявлений через avito-library (Этап 5)
│   ├── object_task_manager.py # Управление очередью object_tasks (Этап 5)
│   ├── state_machine.py       # Управление состояниями артикулов
│   ├── proxy_manager.py       # Управление пулом прокси
│   ├── detector_handler.py    # Обработка состояний детекторов
│   ├── detectors.py           # Константы детекторов из avito-library
│   ├── heartbeat_manager.py   # Проверка зависших задач
│   ├── xvfb_manager.py        # Управление виртуальными дисплеями
│   ├── database.py            # Подключение к PostgreSQL
│   ├── config.py              # Конфигурация системы
│   └── docker-compose.yml     # Docker Compose конфигурация
│
└── scripts/                   # Вспомогательные скрипты
    ├── load_articulums.py     # Загрузка артикулов в БД
    ├── load_proxies.py        # Загрузка прокси в БД
    ├── clear_tables.py        # Очистка таблиц
    ├── dashboard.py           # Дашборд состояния системы
    ├── create_db.py           # Создание/миграция схемы БД
    ├── schema.sql             # Схема БД
    └── data/                  # Данные для загрузки
        ├── articulums.txt
        └── proxies.txt
```

### Зависимости

- Python 3.11+
- PostgreSQL 16
- Playwright Chromium (`playwright install chromium`)
- avito-library (устанавливается из GitHub)
- asyncpg, openai (для Gemini)

### Основные файлы кода

**Оркестрация:**
- [main.py](container/main.py) - Точка входа, создает Xvfb дисплеи, запускает воркеры, heartbeat checker, создает object_tasks при старте
- [browser_worker.py](container/browser_worker.py) - Browser Worker с динамическим переключением между catalog и object задачами

**Парсинг:**
- [catalog_parser.py](container/catalog_parser.py) - Парсинг каталогов через avito-library
- [object_parser.py](container/object_parser.py) - Парсинг карточек объявлений через parse_card (Этап 5)

**Управление задачами:**
- [catalog_task_manager.py](container/catalog_task_manager.py) - Атомарная выдача и управление catalog_tasks
- [object_task_manager.py](container/object_task_manager.py) - Атомарная выдача и управление object_tasks (Этап 5)

**Инфраструктура:**
- [state_machine.py](container/state_machine.py) - Атомарные переходы состояний артикулов
- [detector_handler.py](container/detector_handler.py) - Универсальная обработка детекторов для catalog и object
- [heartbeat_manager.py](container/heartbeat_manager.py) - Проверка зависших catalog_tasks и object_tasks
- [proxy_manager.py](container/proxy_manager.py) - Управление пулом прокси
- [config.py](container/config.py) - Все константы и переменные окружения

**Документация:**
- [schema.sql](scripts/schema.sql) - Схема БД с таблицами и индексами
- [architecture.md](architecture.md) - Детальная архитектура и механики системы
- [docs/avito-library.md](docs/avito-library.md) - Документация по avito-library

---

## Обзор проекта

Автоматизированная система для парсинга объявлений с Авито по артикулам с многоуровневой валидацией и распределенной обработкой через независимые воркеры.

**Основные принципы:**
- Никогда не врать - если что-то неизвестно, так и говорить
- Комментарии должны быть краткими и просто описывать, что делает блок кода (без лишних подробностей)
- При необходимости использовать web search
- Не создавать версии проекта и не упоминать версионирование
- Всегда актуализировать документацию
  
**ВАЖНО:** Проект состоит из двух основных папок: `container` и `scripts`

**КРИТИЧЕСКИ ВАЖНО:**
- Все команды docker compose ДОЛЖНЫ выполняться ТОЛЬКО из каталога контейнера (`container/`)
- Папка `container/` - основная рабочая логика программы (воркеры, модули, бизнес-логика)
- Папка `scripts/` - ТОЛЬКО вспомогательные скрипты (загрузка артикулов/прокси в БД, очистка таблиц, дашборды)

Вся разная логика должна разделяться на разные файы

Важно уточить, что во время работы можно менять структуру бд
Сами таблицы созадются и меняются постеменно, по мере необходмсоти

Используем самые новые версии библиотек

Браузер и страница
Один воркер = один DISPLAY = один браузер = одна страница в момент времени
DISPLAY не меняется в течение жизни воркера
Страница живет максимально долго и обрабатывает много задач подряд
После каждого page.goto() обязательно вызывается детектор состояния
При смене прокси закрывается весь браузер, а не только страница
Детекторы
Детекторы проверяются в порядке приоритета: успешные состояния → проблемы
Одна общая функция обработки детекторов для catalog и object задач (без дублирования кода)


Прокси
Блокировка прокси постоянная (механизма разблокировки нет)
Счетчик последовательных ошибок: 3 transient errors подряд → постоянная блокировка
  - Transient errors: ERR_TIMED_OUT, ERR_CONNECTION_CLOSED, ERR_CONNECTION_RESET и т.д.
  - Счетчик сбрасывается после успешного выполнения любой задачи
  - Permanent errors (403, AUTH) блокируют прокси сразу (без счетчика)
При блокировке прокси (403, AUTH) воркер меняет прокси БЕЗ возврата задачи
При нерешенной капче прокси возвращается в пул вместе с задачей
Атомарная выдача прокси через SELECT FOR UPDATE SKIP LOCKED
Задачи
Атомарная выдача задач (одна задача = один воркер)
Динамическая приоритизация на основе буфера каталогов (CATALOG_BUFFER_SIZE):
  - Если buffer < CATALOG_BUFFER_SIZE → приоритет catalog_task
  - Если buffer >= CATALOG_BUFFER_SIZE → приоритет object_task
  - Буфер = количество артикулов в VALIDATED с pending object_tasks
Все воркеры могут брать любые задачи (нет жестких лимитов)
Нет retry-счетчиков (задача может пройти через неограниченное количество прокси)

State Machine
Переходы только вперед (откатов нет)
Артикул не переходит в CATALOG_PARSED пока ВСЕ страницы каталога не обработаны
Объявления одного артикула валидируются как единый батч
Записи в object_tasks создаются ТОЛЬКО после перехода в VALIDATED


Heartbeat
Воркер периодически обновляет heartbeat для текущей задачи
Фоновая задача проверяет обе таблицы (catalog_tasks и object_tasks)
При просрочке heartbeat задача возвращается в pending с сохранением чекпоинта


Воркеры
Воркеры НЕ взаимодействуют напрямую (только через PostgreSQL)
Воркеры динамически переключаются между catalog и object задачами на основе буфера
Режим воркера (catalog/object) хранится в памяти процесса и меняется при каждой задаче



Validation Workers
Validation Workers работают БЕЗ браузера (без Playwright, Xvfb, DISPLAY)
Validation Workers берут артикулы целиком по статусу CATALOG_PARSED (не задачи из очереди)
ИИ-валидация применяется только к объявлениям, прошедшим механическую
Обе валидации (механическая и ИИ) должны пройти для создания object_task
Graceful degradation: если нет GEMINI_API_KEY — программа останаваливается


Парсинг через avito-library
parse_catalog_until_complete сам решает капчи (воркер не решает вручную)
parse_catalog_until_complete работает батчами страниц (не постранично)
page_provider вызывается только при блокировке прокси (не при капче)
Парсинг продолжается с полученной страницы (не перезапуск сначала)


Чекпоинты
Чекпоинт = номер последней обработанной страницы каталога
При heartbeat timeout новый воркер продолжает с чекпоинта (не начинает сначала)
Чекпоинт сохраняется в catalog_tasks

Обработка детекторов
Детекторы вызываются после значимых действий (не только после goto)
REMOVED_DETECTOR_ID → задача invalid (не failed)
NOT_DETECTED_STATE_ID → задача failed без retry
Исключения page.goto() (timeout, network error) → задача возвращается в очередь


Управление ресурсами
При отсутствии свободных прокси воркер приостанавливает взятие задач и ждет
При падении воркера: освобождение ресурсов (прокси, задачи), затем перезапуск
Прокси помечается «используется» с привязкой к worker_id
Прокси помечается «заблокирован» в БД (постоянно)


Система
Создание TOTAL_BROWSER_WORKERS дисплеев Xvfb при старте контейнера
Воркеры запускаются через asyncio.create_subprocess_exec
Главный процесс проверяет статус subprocesses для мониторинга
Heartbeat-механизм проверяет обе таблицы (catalog_tasks и object_tasks)


ЗАПРЕЩЕНО
Использовать requests/aiohttp (только Playwright для всех сетевых операций)
Дублировать логику обработки детекторов между catalog и object
Откатывать артикул назад по state machine
Разблокировать прокси после блокировки
Использовать счетчики retry для задач
Менять DISPLAY у воркера во время работы
Иметь больше одной страницы у воркера одновременно

---

## MULTI-SERVER РАЗВЕРТЫВАНИЕ

Система полностью поддерживает запуск на нескольких серверах одновременно.

### Как это работает

**Глобальные Worker ID:**
- Каждый контейнер генерирует уникальный Container ID на основе hostname
- Worker ID формируется как: `{container_id}_{local_worker_id}`
- Пример: `a1b2c3d4_1`, `a1b2c3d4_2` (Browser Workers), `a1b2c3d4_V1` (Validation Workers)

**Атомарность операций:**
- Задачи выдаются атомарно через SELECT FOR UPDATE SKIP LOCKED
- Прокси выдаются атомарно через SELECT FOR UPDATE SKIP LOCKED
- Контейнеры на разных серверах безопасно конкурируют за ресурсы

**Heartbeat механизм:**
- Каждый контейнер запускает свой heartbeat checker
- Освобождение ресурсов происходит по уникальному worker_id
- Нет конфликтов между контейнерами

### Развертывание на нескольких серверах

1. **Подготовка БД (один раз):**
```bash
# На одном из серверов выполнить миграцию
python scripts/migrate_worker_id.py
```

2. **Настройка серверов:**
- У каждого сервера должен быть уникальный hostname
- Все серверы подключаются к одной PostgreSQL БД
- Настройте переменные окружения в docker-compose.yml

3. **Запуск контейнеров:**
```bash
# На каждом сервере
cd container/
docker compose up -d
```

4. **Мониторинг:**
- Worker ID в логах покажет контейнер: `Worker#a1b2c3d4_1`
- Dashboard покажет воркеры со всех серверов

### Горизонтальное масштабирование

**Автоматическая балансировка:**
- Воркеры со всех серверов берут задачи из общей очереди
- Нагрузка распределяется автоматически
- Общий пул прокси для всех серверов

**Fault tolerance:**
- Падение одного контейнера не влияет на другие
- Heartbeat механизм вернет задачи в очередь
- Другие контейнеры продолжат работу

**Линейное масштабирование:**
- Добавляйте серверы для увеличения производительности
- Каждый сервер добавляет TOTAL_BROWSER_WORKERS + TOTAL_VALIDATION_WORKERS
- Ограничение только по количеству доступных прокси

### Требования

- PostgreSQL доступен со всех серверов
- Уникальные hostname на каждом сервере
- Синхронизированное время (NTP) между серверами
- Общая сеть или VPN между серверами и БД